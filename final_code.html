
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Code- Shubham Jain &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'final_code';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Project Links" href="Projectlinks.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="My sample book - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="resume.html">Resume</a></li>
<li class="toctree-l1"><a class="reference internal" href="video.html">Project Video</a></li>

<li class="toctree-l1"><a class="reference internal" href="Projectlinks.html">Project Links</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Code- Shubham Jain</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/final_code.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Code- Shubham Jain</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="code-shubham-jain">
<h1>Code- Shubham Jain<a class="headerlink" href="#code-shubham-jain" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">sqlite3</span>

<span class="c1"># File path</span>
<span class="n">file_path</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;C:\Users\proig\Downloads\winequalityN.csv&quot;</span>

<span class="c1"># Step 1: Analyze missing values</span>
<span class="n">missing_counts</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">total_rows</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">header</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Read the file and count missing values</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictReader</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
    <span class="n">header</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">fieldnames</span>
    <span class="n">missing_counts</span> <span class="o">=</span> <span class="p">{</span><span class="n">col</span><span class="p">:</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">header</span><span class="p">}</span>

    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">:</span>
        <span class="n">total_rows</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">header</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">row</span><span class="p">[</span><span class="n">col</span><span class="p">]:</span>  <span class="c1"># Empty or missing value</span>
                <span class="n">missing_counts</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="c1"># Display missing value counts</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Missing Values in Each Column:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">missing_counts</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> missing (</span><span class="si">{</span><span class="p">(</span><span class="n">count</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">total_rows</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%)&quot;</span><span class="p">)</span>

<span class="c1"># Step 2: Calculate column means for handling missing values</span>
<span class="n">column_sums</span> <span class="o">=</span> <span class="p">{</span><span class="n">col</span><span class="p">:</span> <span class="mf">0.0</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">header</span> <span class="k">if</span> <span class="n">col</span> <span class="o">!=</span> <span class="s1">&#39;type&#39;</span><span class="p">}</span>
<span class="n">row_counts</span> <span class="o">=</span> <span class="p">{</span><span class="n">col</span><span class="p">:</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">header</span> <span class="k">if</span> <span class="n">col</span> <span class="o">!=</span> <span class="s1">&#39;type&#39;</span><span class="p">}</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictReader</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">column_sums</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="n">col</span><span class="p">]:</span>
                    <span class="n">column_sums</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>
                    <span class="n">row_counts</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                <span class="k">continue</span>

<span class="n">column_means</span> <span class="o">=</span> <span class="p">{</span><span class="n">col</span><span class="p">:</span> <span class="n">column_sums</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">/</span> <span class="n">row_counts</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">column_sums</span><span class="p">}</span>

<span class="c1"># Step 3: Normalize data into a SQLite database</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s1">&#39;wine_quality_normalized.db&#39;</span><span class="p">)</span>
<span class="n">cursor</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">cursor</span><span class="p">()</span>

<span class="c1"># Create tables</span>
<span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">CREATE TABLE IF NOT EXISTS Wine (</span>
<span class="s1">    wine_id INTEGER PRIMARY KEY AUTOINCREMENT,</span>
<span class="s1">    type TEXT NOT NULL</span>
<span class="s1">);</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>

<span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">CREATE TABLE IF NOT EXISTS QualityMetrics (</span>
<span class="s1">    metric_id INTEGER PRIMARY KEY AUTOINCREMENT,</span>
<span class="s1">    wine_id INTEGER,</span>
<span class="s1">    fixed_acidity REAL,</span>
<span class="s1">    volatile_acidity REAL,</span>
<span class="s1">    citric_acid REAL,</span>
<span class="s1">    residual_sugar REAL,</span>
<span class="s1">    chlorides REAL,</span>
<span class="s1">    free_sulfur_dioxide REAL,</span>
<span class="s1">    total_sulfur_dioxide REAL,</span>
<span class="s1">    density REAL,</span>
<span class="s1">    pH REAL,</span>
<span class="s1">    sulphates REAL,</span>
<span class="s1">    alcohol REAL,</span>
<span class="s1">    quality INTEGER,</span>
<span class="s1">    FOREIGN KEY (wine_id) REFERENCES Wine(wine_id)</span>
<span class="s1">);</span>
<span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>

<span class="c1"># Insert data into tables</span>
<span class="n">wine_cache</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">def</span> <span class="nf">safe_float</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">column_sum</span><span class="p">,</span> <span class="n">row_count</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">if</span> <span class="n">value</span> <span class="k">else</span> <span class="n">column_sum</span> <span class="o">/</span> <span class="n">row_count</span>
    <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">column_sum</span> <span class="o">/</span> <span class="n">row_count</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictReader</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">:</span>
        <span class="c1"># Insert into Wine table</span>
        <span class="n">wine_type</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;type&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">wine_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">wine_cache</span><span class="p">:</span>
            <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s2">&quot;INSERT INTO Wine (type) VALUES (?)&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">wine_type</span><span class="p">,))</span>
            <span class="n">conn</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
            <span class="n">wine_cache</span><span class="p">[</span><span class="n">wine_type</span><span class="p">]</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">lastrowid</span>
        <span class="n">wine_id</span> <span class="o">=</span> <span class="n">wine_cache</span><span class="p">[</span><span class="n">wine_type</span><span class="p">]</span>

        <span class="c1"># Insert into QualityMetrics table</span>
        <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">            INSERT INTO QualityMetrics (</span>
<span class="s1">                wine_id, fixed_acidity, volatile_acidity, citric_acid, residual_sugar, chlorides,</span>
<span class="s1">                free_sulfur_dioxide, total_sulfur_dioxide, density, pH, sulphates, alcohol, quality</span>
<span class="s1">            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)</span>
<span class="s1">        &#39;&#39;&#39;</span><span class="p">,</span> <span class="p">(</span>
            <span class="n">wine_id</span><span class="p">,</span>
            <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;fixed acidity&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;fixed acidity&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;fixed acidity&#39;</span><span class="p">]),</span>
            <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;volatile acidity&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;volatile acidity&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;volatile acidity&#39;</span><span class="p">]),</span>
            <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;citric acid&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;citric acid&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;citric acid&#39;</span><span class="p">]),</span>
            <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;residual sugar&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;residual sugar&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;residual sugar&#39;</span><span class="p">]),</span>
            <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;chlorides&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;chlorides&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;chlorides&#39;</span><span class="p">]),</span>
            <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;free sulfur dioxide&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;free sulfur dioxide&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;free sulfur dioxide&#39;</span><span class="p">]),</span>
            <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;total sulfur dioxide&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;total sulfur dioxide&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;total sulfur dioxide&#39;</span><span class="p">]),</span>
            <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;density&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;density&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;density&#39;</span><span class="p">]),</span>
            <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;pH&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;pH&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;pH&#39;</span><span class="p">]),</span>
            <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;sulphates&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;sulphates&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;sulphates&#39;</span><span class="p">]),</span>
            <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;alcohol&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;alcohol&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;alcohol&#39;</span><span class="p">]),</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">])</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="p">))</span>
        <span class="n">conn</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>

<span class="c1"># Close the database connection</span>
<span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Database created and populated in 3NF.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Missing Values in Each Column:
type: 0 missing (0.00%)
fixed acidity: 10 missing (0.15%)
volatile acidity: 8 missing (0.12%)
citric acid: 3 missing (0.05%)
residual sugar: 2 missing (0.03%)
chlorides: 2 missing (0.03%)
free sulfur dioxide: 0 missing (0.00%)
total sulfur dioxide: 0 missing (0.00%)
density: 0 missing (0.00%)
pH: 9 missing (0.14%)
sulphates: 4 missing (0.06%)
alcohol: 0 missing (0.00%)
quality: 0 missing (0.00%)
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">99</span>
<span class="g g-Whitespace">     </span><span class="mi">96</span>         <span class="n">wine_id</span> <span class="o">=</span> <span class="n">wine_cache</span><span class="p">[</span><span class="n">wine_type</span><span class="p">]</span>
<span class="g g-Whitespace">     </span><span class="mi">98</span>         <span class="c1"># Insert into QualityMetrics table</span>
<span class="ne">---&gt; </span><span class="mi">99</span>         <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;</span>
<span class="g g-Whitespace">    </span><span class="mi">100</span><span class="s1">             INSERT INTO QualityMetrics (</span>
<span class="g g-Whitespace">    </span><span class="mi">101</span><span class="s1">                 wine_id, fixed_acidity, volatile_acidity, citric_acid, residual_sugar, chlorides,</span>
<span class="g g-Whitespace">    </span><span class="mi">102</span><span class="s1">                 free_sulfur_dioxide, total_sulfur_dioxide, density, pH, sulphates, alcohol, quality</span>
<span class="g g-Whitespace">    </span><span class="mi">103</span><span class="s1">             ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)</span>
<span class="g g-Whitespace">    </span><span class="mi">104</span><span class="s1">         &#39;&#39;&#39;</span><span class="p">,</span> <span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">105</span>             <span class="n">wine_id</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">106</span>             <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;fixed acidity&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;fixed acidity&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;fixed acidity&#39;</span><span class="p">]),</span>
<span class="g g-Whitespace">    </span><span class="mi">107</span>             <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;volatile acidity&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;volatile acidity&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;volatile acidity&#39;</span><span class="p">]),</span>
<span class="g g-Whitespace">    </span><span class="mi">108</span>             <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;citric acid&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;citric acid&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;citric acid&#39;</span><span class="p">]),</span>
<span class="g g-Whitespace">    </span><span class="mi">109</span>             <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;residual sugar&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;residual sugar&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;residual sugar&#39;</span><span class="p">]),</span>
<span class="g g-Whitespace">    </span><span class="mi">110</span>             <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;chlorides&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;chlorides&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;chlorides&#39;</span><span class="p">]),</span>
<span class="g g-Whitespace">    </span><span class="mi">111</span>             <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;free sulfur dioxide&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;free sulfur dioxide&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;free sulfur dioxide&#39;</span><span class="p">]),</span>
<span class="g g-Whitespace">    </span><span class="mi">112</span>             <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;total sulfur dioxide&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;total sulfur dioxide&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;total sulfur dioxide&#39;</span><span class="p">]),</span>
<span class="g g-Whitespace">    </span><span class="mi">113</span>             <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;density&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;density&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;density&#39;</span><span class="p">]),</span>
<span class="g g-Whitespace">    </span><span class="mi">114</span>             <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;pH&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;pH&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;pH&#39;</span><span class="p">]),</span>
<span class="g g-Whitespace">    </span><span class="mi">115</span>             <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;sulphates&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;sulphates&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;sulphates&#39;</span><span class="p">]),</span>
<span class="g g-Whitespace">    </span><span class="mi">116</span>             <span class="n">safe_float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;alcohol&#39;</span><span class="p">],</span> <span class="n">column_sums</span><span class="p">[</span><span class="s1">&#39;alcohol&#39;</span><span class="p">],</span> <span class="n">row_counts</span><span class="p">[</span><span class="s1">&#39;alcohol&#39;</span><span class="p">]),</span>
<span class="g g-Whitespace">    </span><span class="mi">117</span>             <span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">])</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">118</span>         <span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">119</span>         <span class="n">conn</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">121</span> <span class="c1"># Close the database connection</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sqlite3</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Connect to the database</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s1">&#39;wine_quality_normalized.db&#39;</span><span class="p">)</span>

<span class="c1"># SQL join query to combine `Wine` and `QualityMetrics` tables</span>
<span class="n">query</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;</span>
<span class="s1">SELECT</span>
<span class="s1">    wm.metric_id,</span>
<span class="s1">    w.type AS wine_type,</span>
<span class="s1">    wm.fixed_acidity,</span>
<span class="s1">    wm.volatile_acidity,</span>
<span class="s1">    wm.citric_acid,</span>
<span class="s1">    wm.residual_sugar,</span>
<span class="s1">    wm.chlorides,</span>
<span class="s1">    wm.free_sulfur_dioxide,</span>
<span class="s1">    wm.total_sulfur_dioxide,</span>
<span class="s1">    wm.density,</span>
<span class="s1">    wm.pH,</span>
<span class="s1">    wm.sulphates,</span>
<span class="s1">    wm.alcohol,</span>
<span class="s1">    wm.quality</span>
<span class="s1">FROM</span>
<span class="s1">    QualityMetrics wm</span>
<span class="s1">JOIN</span>
<span class="s1">    Wine w ON wm.wine_id = w.wine_id;</span>
<span class="s1">&#39;&#39;&#39;</span>

<span class="c1"># Execute the query and load data into a Pandas DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_sql_query</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">conn</span><span class="p">)</span>

<span class="c1"># Close the database connection</span>
<span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># Display the DataFrame</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      metric_id wine_type  fixed_acidity  volatile_acidity  citric_acid  \
0             1     white            7.0             0.270         0.36   
1             2     white            6.3             0.300         0.34   
2             3     white            8.1             0.280         0.40   
3             4     white            7.2             0.230         0.32   
4             5     white            7.2             0.230         0.32   
...         ...       ...            ...               ...          ...   
6492       6493       red            6.2             0.600         0.08   
6493       6494       red            5.9             0.550         0.10   
6494       6495       red            6.3             0.510         0.13   
6495       6496       red            5.9             0.645         0.12   
6496       6497       red            6.0             0.310         0.47   

      residual_sugar  chlorides  free_sulfur_dioxide  total_sulfur_dioxide  \
0               20.7      0.045                 45.0                 170.0   
1                1.6      0.049                 14.0                 132.0   
2                6.9      0.050                 30.0                  97.0   
3                8.5      0.058                 47.0                 186.0   
4                8.5      0.058                 47.0                 186.0   
...              ...        ...                  ...                   ...   
6492             2.0      0.090                 32.0                  44.0   
6493             2.2      0.062                 39.0                  51.0   
6494             2.3      0.076                 29.0                  40.0   
6495             2.0      0.075                 32.0                  44.0   
6496             3.6      0.067                 18.0                  42.0   

      density    pH  sulphates  alcohol  quality  
0     1.00100  3.00   0.450000      8.8        6  
1     0.99400  3.30   0.490000      9.5        6  
2     0.99510  3.26   0.440000     10.1        6  
3     0.99560  3.19   0.400000      9.9        6  
4     0.99560  3.19   0.400000      9.9        6  
...       ...   ...        ...      ...      ...  
6492  0.99490  3.45   0.580000     10.5        5  
6493  0.99512  3.52   0.531215     11.2        6  
6494  0.99574  3.42   0.750000     11.0        6  
6495  0.99547  3.57   0.710000     10.2        5  
6496  0.99549  3.39   0.660000     11.0        6  

[6497 rows x 14 columns]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">sqlite3</span>

<span class="c1"># Load data from the database</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">sqlite3</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="s1">&#39;wine_quality_normalized.db&#39;</span><span class="p">)</span>
<span class="n">query</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;</span>
<span class="s1">SELECT</span>
<span class="s1">    w.type AS wine_type,</span>
<span class="s1">    wm.fixed_acidity,</span>
<span class="s1">    wm.volatile_acidity,</span>
<span class="s1">    wm.citric_acid,</span>
<span class="s1">    wm.residual_sugar,</span>
<span class="s1">    wm.chlorides,</span>
<span class="s1">    wm.free_sulfur_dioxide,</span>
<span class="s1">    wm.total_sulfur_dioxide,</span>
<span class="s1">    wm.density,</span>
<span class="s1">    wm.pH,</span>
<span class="s1">    wm.sulphates,</span>
<span class="s1">    wm.alcohol,</span>
<span class="s1">    wm.quality</span>
<span class="s1">FROM</span>
<span class="s1">    QualityMetrics wm</span>
<span class="s1">JOIN</span>
<span class="s1">    Wine w ON wm.wine_id = w.wine_id;</span>
<span class="s1">&#39;&#39;&#39;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_sql_query</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">conn</span><span class="p">)</span>
<span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># Analyze the distribution of &#39;quality&#39;</span>
<span class="n">quality_counts</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Distribution of &#39;quality&#39;:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">quality_counts</span><span class="p">)</span>

<span class="c1"># Visualize the distribution</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">quality_counts</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">quality_counts</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Quality&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Count&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of Wine Quality&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Decide if stratification is needed (e.g., for imbalanced distributions)</span>
<span class="k">if</span> <span class="p">(</span><span class="n">quality_counts</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">/</span> <span class="n">quality_counts</span><span class="o">.</span><span class="n">min</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># Arbitrary threshold for imbalance</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The dataset is imbalanced; stratification will be performed.&quot;</span><span class="p">)</span>

<span class="c1"># Train/test split</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">]</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># Verify the stratification</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Train set quality distribution:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">sort_index</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Test set quality distribution:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">sort_index</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Distribution of &#39;quality&#39;:
quality
3      30
4     216
5    2138
6    2836
7    1079
8     193
9       5
Name: count, dtype: int64
</pre></div>
</div>
<img alt="_images/1a339e6d7d199c01db9a7dc0a88480bc7036a891a2d998a46ec5a4cdac859453.png" src="_images/1a339e6d7d199c01db9a7dc0a88480bc7036a891a2d998a46ec5a4cdac859453.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The dataset is imbalanced; stratification will be performed.

Train set quality distribution:
quality
3    0.004618
4    0.033288
5    0.329036
6    0.436598
7    0.166057
8    0.029632
9    0.000770
Name: proportion, dtype: float64

Test set quality distribution:
quality
3    0.004615
4    0.033077
5    0.329231
6    0.436154
7    0.166154
8    0.030000
9    0.000769
Name: proportion, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ydata_profiling</span> <span class="kn">import</span> <span class="n">ProfileReport</span>

<span class="c1"># Generate a profile report for the dataset</span>
<span class="n">profile</span> <span class="o">=</span> <span class="n">ProfileReport</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Wine Quality Data Profiling&quot;</span><span class="p">,</span> <span class="n">explorative</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Save the report to an HTML file to view it in the browser</span>
<span class="n">profile</span><span class="o">.</span><span class="n">to_file</span><span class="p">(</span><span class="s2">&quot;wine_quality_profile.html&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "95edc5ca85414403bc998f99569f0130", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "8893c05a128d432b964b3408ef94db37", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "99a37ba62cba483dbe6f875108b7deee", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "20a6aa743f974e38bfc9cc7c02193257", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># If you&#39;re in a Jupyter notebook, use this line to render plots inline</span>
<span class="o">%</span><span class="k">matplotlib</span> inline  

<span class="c1"># If you&#39;re using a script or terminal environment and need GUI support, switch the backend</span>
<span class="c1">#plt.switch_backend(&#39;TkAgg&#39;)  # Uncomment if using script or terminal with GUI</span>

<span class="c1"># Drop categorical columns, assuming &#39;wine_type&#39; is a categorical column</span>
<span class="n">df_clean</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">exclude</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;object&#39;</span><span class="p">])</span>  <span class="c1"># This will drop non-numeric columns</span>

<span class="c1"># Calculate the correlation matrix</span>
<span class="n">correlation_matrix</span> <span class="o">=</span> <span class="n">df_clean</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>

<span class="c1"># Plot the correlation matrix</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;.2f&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Correlation Matrix&quot;</span><span class="p">)</span>

<span class="c1"># Save the plot to a file</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;correlation_matrix.png&#39;</span><span class="p">)</span>

<span class="c1"># Show the plot (if working in an environment that supports it)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ed403894202af9ac25251964578500b82036a1b1baec3a33a3b861b14f18c912.png" src="_images/ed403894202af9ac25251964578500b82036a1b1baec3a33a3b861b14f18c912.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">missing_values</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="c1"># Display missing values per column</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Missing Values in Each Column:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">missing_values</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Missing Values in Each Column:
wine_type               0
fixed_acidity           0
volatile_acidity        0
citric_acid             0
residual_sugar          0
chlorides               0
free_sulfur_dioxide     0
total_sulfur_dioxide    0
density                 0
pH                      0
sulphates               0
alcohol                 0
quality                 0
dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">thresholds</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;fixed_acidity&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">16.0</span><span class="p">),</span>  <span class="c1"># (min, max)</span>
    <span class="s1">&#39;volatile_acidity&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">),</span>
    <span class="s1">&#39;citric_acid&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="s1">&#39;residual_sugar&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">15.0</span><span class="p">),</span>
    <span class="s1">&#39;chlorides&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span>
    <span class="s1">&#39;free_sulfur_dioxide&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">60</span><span class="p">),</span>
    <span class="s1">&#39;total_sulfur_dioxide&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span>
    <span class="s1">&#39;density&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.99</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">),</span>
    <span class="s1">&#39;pH&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">2.9</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">),</span>
    <span class="s1">&#39;sulphates&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.33</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">),</span>
    <span class="s1">&#39;alcohol&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">15</span><span class="p">),</span>
<span class="p">}</span>

<span class="c1"># Function to check for capped values</span>
<span class="k">def</span> <span class="nf">check_capped_values</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">thresholds</span><span class="p">):</span>
    <span class="n">capped_values</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="k">for</span> <span class="n">column</span><span class="p">,</span> <span class="p">(</span><span class="n">min_val</span><span class="p">,</span> <span class="n">max_val</span><span class="p">)</span> <span class="ow">in</span> <span class="n">thresholds</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># Check for values below the min or above the max</span>
        <span class="n">lower_capped</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">min_val</span>
        <span class="n">upper_capped</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">max_val</span>
        
        <span class="c1"># Store results</span>
        <span class="n">capped_values</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;below_min&#39;</span><span class="p">:</span> <span class="n">lower_capped</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
            <span class="s1">&#39;above_max&#39;</span><span class="p">:</span> <span class="n">upper_capped</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="p">}</span>
    
    <span class="k">return</span> <span class="n">capped_values</span>

<span class="c1"># Check capped values</span>
<span class="n">capped_values</span> <span class="o">=</span> <span class="n">check_capped_values</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">thresholds</span><span class="p">)</span>

<span class="c1"># Display results</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Capped Values (below min or above max):&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">column</span><span class="p">,</span> <span class="n">counts</span> <span class="ow">in</span> <span class="n">capped_values</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s2">: Below min: </span><span class="si">{</span><span class="n">counts</span><span class="p">[</span><span class="s1">&#39;below_min&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">, Above max: </span><span class="si">{</span><span class="n">counts</span><span class="p">[</span><span class="s1">&#39;above_max&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Capped Values (below min or above max):
fixed_acidity: Below min: 2, Above max: 0
volatile_acidity: Below min: 6, Above max: 1
citric_acid: Below min: 0, Above max: 2
residual_sugar: Below min: 0, Above max: 324
chlorides: Below min: 0, Above max: 333
free_sulfur_dioxide: Below min: 0, Above max: 350
total_sulfur_dioxide: Below min: 0, Above max: 393
density: Below min: 345, Above max: 0
pH: Below min: 79, Above max: 2
sulphates: Below min: 172, Above max: 0
alcohol: Below min: 0, Above max: 0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="c1"># Assuming df is your dataset and &#39;wine_type&#39;, &#39;metric_id&#39;, and &#39;quality&#39; are the columns to exclude</span>
<span class="n">df_filtered</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;wine_type&#39;</span><span class="p">])</span>

<span class="c1"># 1. Plot histograms for all numerical features</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="n">df_filtered</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure size 1500x1200 with 0 Axes&gt;
</pre></div>
</div>
<img alt="_images/c9ea85d2b24b44eee32aae19b6e255f35d46b56b69a84c8569530a9e2e9d23a0.png" src="_images/c9ea85d2b24b44eee32aae19b6e255f35d46b56b69a84c8569530a9e2e9d23a0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>wine_type</th>
      <th>fixed_acidity</th>
      <th>volatile_acidity</th>
      <th>citric_acid</th>
      <th>residual_sugar</th>
      <th>chlorides</th>
      <th>free_sulfur_dioxide</th>
      <th>total_sulfur_dioxide</th>
      <th>density</th>
      <th>pH</th>
      <th>sulphates</th>
      <th>alcohol</th>
      <th>quality</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>white</td>
      <td>7.0</td>
      <td>0.270</td>
      <td>0.36</td>
      <td>20.7</td>
      <td>0.045</td>
      <td>45.0</td>
      <td>170.0</td>
      <td>1.00100</td>
      <td>3.00</td>
      <td>0.450000</td>
      <td>8.8</td>
      <td>6</td>
    </tr>
    <tr>
      <th>1</th>
      <td>white</td>
      <td>6.3</td>
      <td>0.300</td>
      <td>0.34</td>
      <td>1.6</td>
      <td>0.049</td>
      <td>14.0</td>
      <td>132.0</td>
      <td>0.99400</td>
      <td>3.30</td>
      <td>0.490000</td>
      <td>9.5</td>
      <td>6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>white</td>
      <td>8.1</td>
      <td>0.280</td>
      <td>0.40</td>
      <td>6.9</td>
      <td>0.050</td>
      <td>30.0</td>
      <td>97.0</td>
      <td>0.99510</td>
      <td>3.26</td>
      <td>0.440000</td>
      <td>10.1</td>
      <td>6</td>
    </tr>
    <tr>
      <th>3</th>
      <td>white</td>
      <td>7.2</td>
      <td>0.230</td>
      <td>0.32</td>
      <td>8.5</td>
      <td>0.058</td>
      <td>47.0</td>
      <td>186.0</td>
      <td>0.99560</td>
      <td>3.19</td>
      <td>0.400000</td>
      <td>9.9</td>
      <td>6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>white</td>
      <td>7.2</td>
      <td>0.230</td>
      <td>0.32</td>
      <td>8.5</td>
      <td>0.058</td>
      <td>47.0</td>
      <td>186.0</td>
      <td>0.99560</td>
      <td>3.19</td>
      <td>0.400000</td>
      <td>9.9</td>
      <td>6</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>6492</th>
      <td>red</td>
      <td>6.2</td>
      <td>0.600</td>
      <td>0.08</td>
      <td>2.0</td>
      <td>0.090</td>
      <td>32.0</td>
      <td>44.0</td>
      <td>0.99490</td>
      <td>3.45</td>
      <td>0.580000</td>
      <td>10.5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>6493</th>
      <td>red</td>
      <td>5.9</td>
      <td>0.550</td>
      <td>0.10</td>
      <td>2.2</td>
      <td>0.062</td>
      <td>39.0</td>
      <td>51.0</td>
      <td>0.99512</td>
      <td>3.52</td>
      <td>0.531215</td>
      <td>11.2</td>
      <td>6</td>
    </tr>
    <tr>
      <th>6494</th>
      <td>red</td>
      <td>6.3</td>
      <td>0.510</td>
      <td>0.13</td>
      <td>2.3</td>
      <td>0.076</td>
      <td>29.0</td>
      <td>40.0</td>
      <td>0.99574</td>
      <td>3.42</td>
      <td>0.750000</td>
      <td>11.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>6495</th>
      <td>red</td>
      <td>5.9</td>
      <td>0.645</td>
      <td>0.12</td>
      <td>2.0</td>
      <td>0.075</td>
      <td>32.0</td>
      <td>44.0</td>
      <td>0.99547</td>
      <td>3.57</td>
      <td>0.710000</td>
      <td>10.2</td>
      <td>5</td>
    </tr>
    <tr>
      <th>6496</th>
      <td>red</td>
      <td>6.0</td>
      <td>0.310</td>
      <td>0.47</td>
      <td>3.6</td>
      <td>0.067</td>
      <td>18.0</td>
      <td>42.0</td>
      <td>0.99549</td>
      <td>3.39</td>
      <td>0.660000</td>
      <td>11.0</td>
      <td>6</td>
    </tr>
  </tbody>
</table>
<p>6497 rows  13 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="c1"># Assuming df is your DataFrame</span>
<span class="c1"># Step 1: Remove &#39;metric_id&#39; and &#39;wine_type&#39; columns</span>
<span class="n">df_filtered</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span> <span class="s1">&#39;wine_type&#39;</span><span class="p">])</span>

<span class="c1"># Step 2: Identify Outliers using IQR</span>
<span class="k">def</span> <span class="nf">identify_outliers</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="n">outliers</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float64&#39;</span><span class="p">,</span> <span class="s1">&#39;int64&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="c1"># Calculate Q1, Q3 and IQR</span>
        <span class="n">Q1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
        <span class="n">Q3</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="mf">0.75</span><span class="p">)</span>
        <span class="n">IQR</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">-</span> <span class="n">Q1</span>
        
        <span class="c1"># Define the lower and upper bounds for outliers</span>
        <span class="n">lower_bound</span> <span class="o">=</span> <span class="n">Q1</span> <span class="o">-</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span>
        <span class="n">upper_bound</span> <span class="o">=</span> <span class="n">Q3</span> <span class="o">+</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span>
        
        <span class="c1"># Identify outliers</span>
        <span class="n">outliers</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">lower_bound</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">upper_bound</span><span class="p">)]</span>
    
    <span class="k">return</span> <span class="n">outliers</span>

<span class="c1"># Get the outliers in the DataFrame</span>
<span class="n">outliers</span> <span class="o">=</span> <span class="n">identify_outliers</span><span class="p">(</span><span class="n">df_filtered</span><span class="p">)</span>
<span class="k">for</span> <span class="n">feature</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">outliers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Outliers in &#39;</span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s2">&#39;: </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> rows&quot;</span><span class="p">)</span>

<span class="c1"># Step 3: Visualize outliers with boxplots</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">df_filtered</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float64&#39;</span><span class="p">,</span> <span class="s1">&#39;int64&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_filtered</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightgreen&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Boxplot of </span><span class="si">{</span><span class="n">feature</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Outliers in &#39;fixed_acidity&#39;: 357 rows
Outliers in &#39;volatile_acidity&#39;: 376 rows
Outliers in &#39;citric_acid&#39;: 508 rows
Outliers in &#39;residual_sugar&#39;: 118 rows
Outliers in &#39;chlorides&#39;: 286 rows
Outliers in &#39;free_sulfur_dioxide&#39;: 62 rows
Outliers in &#39;total_sulfur_dioxide&#39;: 10 rows
Outliers in &#39;density&#39;: 3 rows
Outliers in &#39;pH&#39;: 73 rows
Outliers in &#39;sulphates&#39;: 191 rows
Outliers in &#39;alcohol&#39;: 3 rows
Outliers in &#39;quality&#39;: 228 rows
</pre></div>
</div>
<img alt="_images/02d09868d6544dd55556d3dab09359f3fca32882cf664121db3e7a297e3a963a.png" src="_images/02d09868d6544dd55556d3dab09359f3fca32882cf664121db3e7a297e3a963a.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert &#39;wine_type&#39; to numerical values, defaulting to 0 for unknown types</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;wine_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;wine_type&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="s1">&#39;white&#39;</span> <span class="k">else</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="s1">&#39;red&#39;</span> <span class="k">else</span> <span class="mi">0</span><span class="p">))</span>

<span class="c1"># Verify the conversion</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;wine_type&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    0
1    0
2    0
3    0
4    0
Name: wine_type, dtype: int64
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>wine_type</th>
      <th>fixed_acidity</th>
      <th>volatile_acidity</th>
      <th>citric_acid</th>
      <th>residual_sugar</th>
      <th>chlorides</th>
      <th>free_sulfur_dioxide</th>
      <th>total_sulfur_dioxide</th>
      <th>density</th>
      <th>pH</th>
      <th>sulphates</th>
      <th>alcohol</th>
      <th>quality</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>7.0</td>
      <td>0.270</td>
      <td>0.36</td>
      <td>20.7</td>
      <td>0.045</td>
      <td>45.0</td>
      <td>170.0</td>
      <td>1.00100</td>
      <td>3.00</td>
      <td>0.450000</td>
      <td>8.8</td>
      <td>6</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>6.3</td>
      <td>0.300</td>
      <td>0.34</td>
      <td>1.6</td>
      <td>0.049</td>
      <td>14.0</td>
      <td>132.0</td>
      <td>0.99400</td>
      <td>3.30</td>
      <td>0.490000</td>
      <td>9.5</td>
      <td>6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>8.1</td>
      <td>0.280</td>
      <td>0.40</td>
      <td>6.9</td>
      <td>0.050</td>
      <td>30.0</td>
      <td>97.0</td>
      <td>0.99510</td>
      <td>3.26</td>
      <td>0.440000</td>
      <td>10.1</td>
      <td>6</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>7.2</td>
      <td>0.230</td>
      <td>0.32</td>
      <td>8.5</td>
      <td>0.058</td>
      <td>47.0</td>
      <td>186.0</td>
      <td>0.99560</td>
      <td>3.19</td>
      <td>0.400000</td>
      <td>9.9</td>
      <td>6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>7.2</td>
      <td>0.230</td>
      <td>0.32</td>
      <td>8.5</td>
      <td>0.058</td>
      <td>47.0</td>
      <td>186.0</td>
      <td>0.99560</td>
      <td>3.19</td>
      <td>0.400000</td>
      <td>9.9</td>
      <td>6</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>6492</th>
      <td>1</td>
      <td>6.2</td>
      <td>0.600</td>
      <td>0.08</td>
      <td>2.0</td>
      <td>0.090</td>
      <td>32.0</td>
      <td>44.0</td>
      <td>0.99490</td>
      <td>3.45</td>
      <td>0.580000</td>
      <td>10.5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>6493</th>
      <td>1</td>
      <td>5.9</td>
      <td>0.550</td>
      <td>0.10</td>
      <td>2.2</td>
      <td>0.062</td>
      <td>39.0</td>
      <td>51.0</td>
      <td>0.99512</td>
      <td>3.52</td>
      <td>0.531215</td>
      <td>11.2</td>
      <td>6</td>
    </tr>
    <tr>
      <th>6494</th>
      <td>1</td>
      <td>6.3</td>
      <td>0.510</td>
      <td>0.13</td>
      <td>2.3</td>
      <td>0.076</td>
      <td>29.0</td>
      <td>40.0</td>
      <td>0.99574</td>
      <td>3.42</td>
      <td>0.750000</td>
      <td>11.0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>6495</th>
      <td>1</td>
      <td>5.9</td>
      <td>0.645</td>
      <td>0.12</td>
      <td>2.0</td>
      <td>0.075</td>
      <td>32.0</td>
      <td>44.0</td>
      <td>0.99547</td>
      <td>3.57</td>
      <td>0.710000</td>
      <td>10.2</td>
      <td>5</td>
    </tr>
    <tr>
      <th>6496</th>
      <td>1</td>
      <td>6.0</td>
      <td>0.310</td>
      <td>0.47</td>
      <td>3.6</td>
      <td>0.067</td>
      <td>18.0</td>
      <td>42.0</td>
      <td>0.99549</td>
      <td>3.39</td>
      <td>0.660000</td>
      <td>11.0</td>
      <td>6</td>
    </tr>
  </tbody>
</table>
<p>6497 rows  13 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dagshub</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="s2">&quot;https://dagshub.com/shubh0000007/my-first-repo.mlflow&quot;</span><span class="p">)</span>
<span class="n">dagshub</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">repo_owner</span><span class="o">=</span><span class="s2">&quot;shubh0000007&quot;</span><span class="p">,</span> <span class="n">repo_name</span><span class="o">=</span><span class="s2">&quot;my-first-repo&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Accessing as shubh0000007
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Initialized MLflow to track repo <span style="color: #008000; text-decoration-color: #008000">"shubh0000007/my-first-repo"</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">Repository shubh0000007/my-first-repo initialized!
</pre>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">StratifiedKFold</span><span class="p">,</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">FunctionTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">f1_score</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>

<span class="c1"># Load your dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">df</span>  <span class="c1"># Replace &#39;df&#39; with your actual DataFrame variable name</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;quality&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Replace &#39;quality&#39; with your target column name</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;quality&quot;</span><span class="p">]</span>  <span class="c1"># Ensure &#39;quality&#39; is your target variable (numeric)</span>

<span class="c1"># Convert numeric target to binary using a threshold</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>  <span class="c1"># You can adjust this threshold to fit your case</span>
<span class="n">y_binary</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>  <span class="c1"># Convert to 0 or 1 based on the threshold</span>

<span class="c1"># Define preprocessors</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">minmax_scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">log_transformer</span> <span class="o">=</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">one_hot_encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>

<span class="c1"># Identify categorical and numerical columns</span>
<span class="n">categorical_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;object&#39;</span><span class="p">,</span> <span class="s1">&#39;category&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>
<span class="n">numerical_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;int64&#39;</span><span class="p">,</span> <span class="s1">&#39;float64&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>

<span class="c1"># Create column transformer</span>
<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;num&quot;</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
            <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">scaler</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">&quot;minmax&quot;</span><span class="p">,</span> <span class="n">minmax_scaler</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">,</span> <span class="n">log_transformer</span><span class="p">)</span>
        <span class="p">]),</span> <span class="n">numerical_features</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="n">one_hot_encoder</span><span class="p">,</span> <span class="n">categorical_features</span><span class="p">)</span>
    <span class="p">])</span>

<span class="c1"># Create pipeline with Logistic Regression</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;preprocessor&quot;</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;classifier&quot;</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># Hyperparameter tuning (for Logistic Regression)</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;classifier__C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="s1">&#39;classifier__penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Fit the GridSearchCV model before accessing best params</span>
<span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_binary</span><span class="p">)</span>

<span class="c1"># Access the best parameters from GridSearchCV after fitting</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span>
<span class="n">best_C</span> <span class="o">=</span> <span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;classifier__C&#39;</span><span class="p">]</span>
<span class="n">best_penalty</span> <span class="o">=</span> <span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;classifier__penalty&#39;</span><span class="p">]</span>

<span class="c1"># Cross-validation and evaluation (using F1-score for classification)</span>
<span class="n">cv_results</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y_binary</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">mean_f1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_results</span><span class="p">)</span>
<span class="n">std_f1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">cv_results</span><span class="p">)</span>

<span class="c1"># Fit the model on the entire training data</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_binary</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Calculate confusion matrix and metrics</span>
<span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_binary</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_binary</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="c1"># Create a new experiment in MLFlow</span>
<span class="n">experiment_name</span> <span class="o">=</span> <span class="s2">&quot;Experiment #1 - Logistic Regression Pipeline!!!&quot;</span>
<span class="k">try</span><span class="p">:</span>
    <span class="c1"># Try to create a new experiment</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">create_experiment</span><span class="p">(</span><span class="n">experiment_name</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="c1"># If the experiment already exists, use it</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="n">experiment_name</span><span class="p">)</span>

<span class="c1"># Log to MLFlow</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="s2">&quot;https://dagshub.com/shubh0000007/my-first-repo.mlflow&quot;</span><span class="p">)</span>  <span class="c1"># Replace with your DagsHub URI</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="n">experiment_name</span><span class="p">)</span>

<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;scalers&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;StandardScaler&quot;</span><span class="p">,</span> <span class="s2">&quot;MinMaxScaler&quot;</span><span class="p">,</span> <span class="s2">&quot;Log Transformation&quot;</span><span class="p">])</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;encoder&quot;</span><span class="p">,</span> <span class="s2">&quot;OneHotEncoder&quot;</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="s2">&quot;LogisticRegression&quot;</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;C&quot;</span><span class="p">,</span> <span class="n">best_C</span><span class="p">)</span>  <span class="c1"># Use the best &#39;C&#39; parameter</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;penalty&quot;</span><span class="p">,</span> <span class="n">best_penalty</span><span class="p">)</span>  <span class="c1"># Use the best penalty parameter</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;mean_f1&quot;</span><span class="p">,</span> <span class="n">mean_f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;std_f1&quot;</span><span class="p">,</span> <span class="n">std_f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;f1_train&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;TP&quot;</span><span class="p">,</span> <span class="n">tp</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;TN&quot;</span><span class="p">,</span> <span class="n">tn</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;FP&quot;</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;FN&quot;</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="s2">&quot;logistic_regression_pipeline&quot;</span><span class="p">)</span>

<span class="c1"># Results</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean F1-Score (CV): </span><span class="si">{</span><span class="n">mean_f1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">std_f1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training F1-Score: </span><span class="si">{</span><span class="n">f1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Confusion Matrix: TP=</span><span class="si">{</span><span class="n">tp</span><span class="si">}</span><span class="s2">, TN=</span><span class="si">{</span><span class="n">tn</span><span class="si">}</span><span class="s2">, FP=</span><span class="si">{</span><span class="n">fp</span><span class="si">}</span><span class="s2">, FN=</span><span class="si">{</span><span class="n">fn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/20 09:10:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> View run incongruous-dove-661 at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/34/runs/b731b47fa0ba48daa51d004c4b832d02
 View experiment at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/34
Mean F1-Score (CV): 0.2570  0.1223
Training F1-Score: 0.2981
Confusion Matrix: TP=251, TN=5064, FP=156, FN=1026
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>xgboost
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: xgboost in c:\users\proig\anaconda3\lib\site-packages (2.1.3)
Requirement already satisfied: numpy in c:\users\proig\anaconda3\lib\site-packages (from xgboost) (1.24.3)
Requirement already satisfied: scipy in c:\users\proig\anaconda3\lib\site-packages (from xgboost) (1.11.1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">FunctionTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">RidgeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">f1_score</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>

<span class="c1"># Load your dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">df</span>  <span class="c1"># Replace &#39;df&#39; with your actual DataFrame variable name</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;quality&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Replace &#39;quality&#39; with your target column name</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;quality&quot;</span><span class="p">]</span>  <span class="c1"># Ensure &#39;quality&#39; is your target variable (numeric)</span>

<span class="c1"># Convert numeric target to binary using a threshold</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">median</span><span class="p">()</span>  <span class="c1"># Adjust this threshold if needed</span>
<span class="n">y_binary</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>  <span class="c1"># Convert to 0 or 1 based on the threshold</span>

<span class="c1"># Define preprocessors</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">minmax_scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">log_transformer</span> <span class="o">=</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">one_hot_encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>

<span class="c1"># Identify categorical and numerical columns</span>
<span class="n">categorical_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;object&#39;</span><span class="p">,</span> <span class="s1">&#39;category&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>
<span class="n">numerical_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;int64&#39;</span><span class="p">,</span> <span class="s1">&#39;float64&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>

<span class="c1"># Create column transformer</span>
<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;num&quot;</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">([</span>
            <span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span> <span class="n">scaler</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">&quot;minmax&quot;</span><span class="p">,</span> <span class="n">minmax_scaler</span><span class="p">),</span>
            <span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">,</span> <span class="n">log_transformer</span><span class="p">)</span>
        <span class="p">]),</span> <span class="n">numerical_features</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;cat&quot;</span><span class="p">,</span> <span class="n">one_hot_encoder</span><span class="p">,</span> <span class="n">categorical_features</span><span class="p">)</span>
    <span class="p">])</span>

<span class="c1"># Define classifiers</span>
<span class="n">classifiers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Logistic Regression&quot;</span><span class="p">:</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">),</span>
    <span class="s2">&quot;Ridge Classifier&quot;</span><span class="p">:</span> <span class="n">RidgeClassifier</span><span class="p">(),</span>
    <span class="s2">&quot;Random Forest&quot;</span><span class="p">:</span> <span class="n">RandomForestClassifier</span><span class="p">(),</span>
    <span class="s2">&quot;XGBoost&quot;</span><span class="p">:</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">use_label_encoder</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;logloss&#39;</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1"># Create a new experiment in MLFlow</span>
<span class="n">experiment_name</span> <span class="o">=</span> <span class="s2">&quot;Experiment #2 - Multiple Classifiers Pipelines!&quot;</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">create_experiment</span><span class="p">(</span><span class="n">experiment_name</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="n">experiment_name</span><span class="p">)</span>

<span class="c1"># Log to MLFlow</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_tracking_uri</span><span class="p">(</span><span class="s2">&quot;https://dagshub.com/shubh0000007/my-first-repo.mlflow&quot;</span><span class="p">)</span>  <span class="c1"># Replace with your DagsHub URI</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="n">experiment_name</span><span class="p">)</span>

<span class="k">for</span> <span class="n">clf_name</span><span class="p">,</span> <span class="n">clf</span> <span class="ow">in</span> <span class="n">classifiers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="c1"># Create pipeline with the classifier</span>
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;preprocessor&quot;</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;classifier&quot;</span><span class="p">,</span> <span class="n">clf</span><span class="p">)</span>
    <span class="p">])</span>

    <span class="c1"># Hyperparameter tuning (using GridSearchCV for simplicity)</span>
    <span class="k">if</span> <span class="n">clf_name</span> <span class="o">==</span> <span class="s2">&quot;Logistic Regression&quot;</span><span class="p">:</span>
        <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;classifier__C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
            <span class="s1">&#39;classifier__penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="k">elif</span> <span class="n">clf_name</span> <span class="o">==</span> <span class="s2">&quot;Ridge Classifier&quot;</span><span class="p">:</span>
        <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;classifier__alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="k">elif</span> <span class="n">clf_name</span> <span class="o">==</span> <span class="s2">&quot;Random Forest&quot;</span><span class="p">:</span>
        <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;classifier__n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span>
            <span class="s1">&#39;classifier__max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="k">elif</span> <span class="n">clf_name</span> <span class="o">==</span> <span class="s2">&quot;XGBoost&quot;</span><span class="p">:</span>
        <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;classifier__max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
            <span class="s1">&#39;classifier__learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]</span>
        <span class="p">}</span>

    <span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="c1"># Fit the GridSearchCV model before accessing best params</span>
    <span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_binary</span><span class="p">)</span>

    <span class="c1"># Access the best parameters from GridSearchCV after fitting</span>
    <span class="n">best_params</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span>

    <span class="c1"># Cross-validation and evaluation (using F1-score for classification)</span>
    <span class="n">cv_results</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y_binary</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">mean_f1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_results</span><span class="p">)</span>
    <span class="n">std_f1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">cv_results</span><span class="p">)</span>

    <span class="c1"># Fit the model on the entire training data</span>
    <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_binary</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="c1"># Calculate confusion matrix and metrics</span>
    <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_binary</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_binary</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;classifier&quot;</span><span class="p">,</span> <span class="n">clf_name</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;best_params&quot;</span><span class="p">,</span> <span class="n">best_params</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;scalers&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;StandardScaler&quot;</span><span class="p">,</span> <span class="s2">&quot;MinMaxScaler&quot;</span><span class="p">,</span> <span class="s2">&quot;Log Transformation&quot;</span><span class="p">])</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;encoder&quot;</span><span class="p">,</span> <span class="s2">&quot;OneHotEncoder&quot;</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="n">clf_name</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;mean_f1&quot;</span><span class="p">,</span> <span class="n">mean_f1</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;std_f1&quot;</span><span class="p">,</span> <span class="n">std_f1</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;f1_train&quot;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;TP&quot;</span><span class="p">,</span> <span class="n">tp</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;TN&quot;</span><span class="p">,</span> <span class="n">tn</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;FP&quot;</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;FN&quot;</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">clf_name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">_pipeline&quot;</span><span class="p">)</span>

    <span class="c1"># Results for the classifier</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">clf_name</span><span class="si">}</span><span class="s2"> - Mean F1-Score (CV): </span><span class="si">{</span><span class="n">mean_f1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">  </span><span class="si">{</span><span class="n">std_f1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">clf_name</span><span class="si">}</span><span class="s2"> - Training F1-Score: </span><span class="si">{</span><span class="n">f1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">clf_name</span><span class="si">}</span><span class="s2"> - Confusion Matrix: TP=</span><span class="si">{</span><span class="n">tp</span><span class="si">}</span><span class="s2">, TN=</span><span class="si">{</span><span class="n">tn</span><span class="si">}</span><span class="s2">, FP=</span><span class="si">{</span><span class="n">fp</span><span class="si">}</span><span class="s2">, FN=</span><span class="si">{</span><span class="n">fn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/20 09:11:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> View run placid-grouse-620 at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/35/runs/8b7c5ccd044c44d59b45b6ca63084dd3
 View experiment at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/35
Logistic Regression - Mean F1-Score (CV): 0.2570  0.1223
Logistic Regression - Training F1-Score: 0.2981
Logistic Regression - Confusion Matrix: TP=251, TN=5064, FP=156, FN=1026
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/20 09:11:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> View run upset-shad-234 at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/35/runs/54d10f0826d74d4cabae45551f0cb546
 View experiment at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/35
Ridge Classifier - Mean F1-Score (CV): 0.1879  0.1462
Ridge Classifier - Training F1-Score: 0.2112
Ridge Classifier - Confusion Matrix: TP=158, TN=5159, FP=61, FN=1119
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/20 09:14:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> View run unequaled-colt-198 at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/35/runs/20f7f520e18d4c8f8978a48f64dc1e7b
 View experiment at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/35
Random Forest - Mean F1-Score (CV): 0.3732  0.1264
Random Forest - Training F1-Score: 1.0000
Random Forest - Confusion Matrix: TP=1277, TN=5220, FP=0, FN=0
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/20 09:15:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> View run big-fly-579 at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/35/runs/6cd349574cce48e281836704344885ed
 View experiment at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/35
XGBoost - Mean F1-Score (CV): 0.3702  0.0861
XGBoost - Training F1-Score: 0.9861
XGBoost - Confusion Matrix: TP=1246, TN=5216, FP=4, FN=31
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>


<span class="c1"># Feature Engineering: Combine features</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;acidity_level&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;fixed_acidity&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;volatile_acidity&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;citric_acid&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;total_sulfur&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;free_sulfur_dioxide&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;total_sulfur_dioxide&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;sugar_alcohol_interaction&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;residual_sugar&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;alcohol&#39;</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;density_ph_interaction&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;density&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;pH&#39;</span><span class="p">]</span>


<span class="c1"># Define features (X) and target variable (y)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;quality&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">]</span>

<span class="c1"># Standardize numerical features</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Split data into training and testing sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Initialize the RandomForestClassifier</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Set or create the MLFlow experiment</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s1">&#39;#3 Feature engineerings!!&#39;</span><span class="p">)</span>

<span class="c1"># Log experiment in MLFlow</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>
    <span class="c1"># Log parameters (e.g., model hyperparameters)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">,</span> <span class="n">rf</span><span class="o">.</span><span class="n">n_estimators</span><span class="p">)</span>
    
    <span class="c1"># Train the model</span>
    <span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Predict on the test set</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    
    <span class="c1"># Calculate metrics</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>  <span class="c1"># &#39;weighted&#39; for multi-class F1 score</span>
    <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    
    <span class="c1"># Log metrics</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;f1_score&#39;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
    
    <span class="c1"># Log the model</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="s1">&#39;random_forest_model&#39;</span><span class="p">)</span>
    
    <span class="c1"># Print out the metrics</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1 Score: </span><span class="si">{</span><span class="n">f1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>

    <span class="c1"># Print TP, TN, FP, FN for each class</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cm</span><span class="p">)):</span>
        <span class="n">tp</span> <span class="o">=</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">fn</span> <span class="o">=</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">tp</span>
        <span class="n">fp</span> <span class="o">=</span> <span class="n">cm</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">tp</span>
        <span class="n">tn</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Class </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True Positives (TP): </span><span class="si">{</span><span class="n">tp</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;False Negatives (FN): </span><span class="si">{</span><span class="n">fn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;False Positives (FP): </span><span class="si">{</span><span class="n">fp</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;True Negatives (TN): </span><span class="si">{</span><span class="n">tn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/20 09:15:36 INFO mlflow.tracking.fluent: Experiment with name &#39;#3 Feature engineerings!!&#39; does not exist. Creating a new experiment.
2024/12/20 09:15:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.6938
F1 Score: 0.6795
Confusion Matrix:
[[  0   0   2   0   0   0]
 [  0   6  23  15   2   0]
 [  0   0 321  97   2   0]
 [  0   0  93 455  31   0]
 [  0   0   5 103 112   1]
 [  0   0   1  14   9   8]]

Class 0:
True Positives (TP): 0
False Negatives (FN): 2
False Positives (FP): 0
True Negatives (TN): 1298

Class 1:
True Positives (TP): 6
False Negatives (FN): 40
False Positives (FP): 0
True Negatives (TN): 1254

Class 2:
True Positives (TP): 321
False Negatives (FN): 99
False Positives (FP): 124
True Negatives (TN): 756

Class 3:
True Positives (TP): 455
False Negatives (FN): 124
False Positives (FP): 229
True Negatives (TN): 492

Class 4:
True Positives (TP): 112
False Negatives (FN): 109
False Positives (FP): 44
True Negatives (TN): 1035

Class 5:
True Positives (TP): 8
False Negatives (FN): 24
False Positives (FP): 1
True Negatives (TN): 1267
 View run placid-grub-198 at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/36/runs/21f12932c0aa4769a3f685f9501ba3b1
 View experiment at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/36
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">VarianceThreshold</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>

<span class="c1"># Assuming df is your dataset</span>
<span class="c1"># Define features (X) and target variable (y)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;quality&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">]</span>

<span class="c1"># Standardize numerical features</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Split data into training and testing sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># MLFlow experiment setup</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s1">&#39;#4 Correlation Threshold, Feature Importance, and Variances!!!&#39;</span><span class="p">)</span>

<span class="c1"># Feature Selection - 1: Correlation Threshold</span>
<span class="k">def</span> <span class="nf">correlation_threshold</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.9</span><span class="p">):</span>
    <span class="c1"># Compute the correlation matrix</span>
    <span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># Create a mask for highly correlated features</span>
    <span class="n">upper_triangle</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">to_drop</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">corr_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">corr_matrix</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))]</span>
    <span class="c1"># Remove features that have a high correlation with others</span>
    <span class="n">removed_features</span> <span class="o">=</span> <span class="p">[</span><span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">to_drop</span><span class="p">]</span>
    <span class="n">X_selected</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">to_drop</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X_selected</span><span class="p">,</span> <span class="n">removed_features</span>

<span class="c1"># Feature Selection - 2: Feature Importance using Random Forest</span>
<span class="k">def</span> <span class="nf">feature_importance</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
    <span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">importances</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">feature_importances_</span>
    <span class="c1"># Select features with importance greater than threshold</span>
    <span class="n">selected_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">importances</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">removed_features</span> <span class="o">=</span> <span class="p">[</span><span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">importances</span><span class="p">))</span> <span class="k">if</span> <span class="n">importances</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">threshold</span><span class="p">]</span>
    <span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="n">selected_features</span><span class="p">]</span>
    <span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[:,</span> <span class="n">selected_features</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">X_train_selected</span><span class="p">,</span> <span class="n">X_test_selected</span><span class="p">,</span> <span class="n">selected_features</span><span class="p">,</span> <span class="n">importances</span><span class="p">,</span> <span class="n">removed_features</span>

<span class="c1"># Feature Selection - 3: Variance Threshold</span>
<span class="k">def</span> <span class="nf">variance_threshold</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="n">selector</span> <span class="o">=</span> <span class="n">VarianceThreshold</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">)</span>
    <span class="n">X_selected</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">removed_features</span> <span class="o">=</span> <span class="p">[</span><span class="n">feature_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">(</span><span class="n">indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">X_selected</span><span class="p">,</span> <span class="n">removed_features</span>

<span class="c1"># Start experiment logging in MLFlow</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>

    <span class="c1"># Log parameters</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s1">&#39;correlation_threshold&#39;</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s1">&#39;importance_threshold&#39;</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s1">&#39;variance_threshold&#39;</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>

    <span class="c1"># Correlation Threshold Selection</span>
    <span class="n">X_corr</span><span class="p">,</span> <span class="n">removed_corr_features</span> <span class="o">=</span> <span class="n">correlation_threshold</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s1">&#39;removed_corr_features&#39;</span><span class="p">,</span> <span class="n">removed_corr_features</span><span class="p">)</span>
    
    <span class="c1"># Variance Threshold Selection</span>
    <span class="n">X_var</span><span class="p">,</span> <span class="n">removed_var_features</span> <span class="o">=</span> <span class="n">variance_threshold</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s1">&#39;removed_var_features&#39;</span><span class="p">,</span> <span class="n">removed_var_features</span><span class="p">)</span>

    <span class="c1"># Feature Importance Selection</span>
    <span class="n">X_imp</span><span class="p">,</span> <span class="n">X_test_imp</span><span class="p">,</span> <span class="n">selected_features</span><span class="p">,</span> <span class="n">importances</span><span class="p">,</span> <span class="n">removed_importance_features</span> <span class="o">=</span> <span class="n">feature_importance</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s1">&#39;selected_features_importance&#39;</span><span class="p">,</span> <span class="n">selected_features</span><span class="p">)</span>

    <span class="c1"># Train the model using RandomForestClassifier on the selected features</span>
    <span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_imp</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_imp</span><span class="p">)</span>

    <span class="c1"># Calculate accuracy and f1 score</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>  <span class="c1"># &#39;weighted&#39; for multi-class F1 score</span>

    <span class="c1"># Log metrics in MLFlow</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;f1_score&#39;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>

    <span class="c1"># Log the model</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="s1">&#39;random_forest_model&#39;</span><span class="p">)</span>

    <span class="c1"># Print results</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1 Score: </span><span class="si">{</span><span class="n">f1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Removed Features due to Correlation Threshold: </span><span class="si">{</span><span class="n">removed_corr_features</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Removed Features due to Variance Threshold: </span><span class="si">{</span><span class="n">removed_var_features</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Removed Features based on Importance: </span><span class="si">{</span><span class="n">removed_importance_features</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Selected Features based on Importance: </span><span class="si">{</span><span class="n">selected_features</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Feature Importances:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">imp</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">importances</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Feature </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">imp</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/20 09:16:11 INFO mlflow.tracking.fluent: Experiment with name &#39;#4 Correlation Threshold, Feature Importance, and Variances!!!&#39; does not exist. Creating a new experiment.
2024/12/20 09:16:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.6946
F1 Score: 0.6792
Removed Features due to Correlation Threshold: [&#39;wine_type&#39;, &#39;fixed_acidity&#39;, &#39;volatile_acidity&#39;, &#39;citric_acid&#39;, &#39;residual_sugar&#39;, &#39;chlorides&#39;, &#39;free_sulfur_dioxide&#39;, &#39;total_sulfur_dioxide&#39;, &#39;density&#39;, &#39;pH&#39;, &#39;sulphates&#39;, &#39;alcohol&#39;, &#39;acidity_level&#39;, &#39;total_sulfur&#39;, &#39;sugar_alcohol_interaction&#39;, &#39;density_ph_interaction&#39;]
Removed Features due to Variance Threshold: []
Removed Features based on Importance: [&#39;wine_type&#39;, &#39;fixed_acidity&#39;]
Selected Features based on Importance: [ 2  3  4  5  6  7  8  9 10 11 12 13 14 15]
Feature Importances:
Feature wine_type: 0.0018
Feature fixed_acidity: 0.0482
Feature volatile_acidity: 0.0832
Feature citric_acid: 0.0622
Feature residual_sugar: 0.0536
Feature chlorides: 0.0671
Feature free_sulfur_dioxide: 0.0640
Feature total_sulfur_dioxide: 0.0638
Feature density: 0.0785
Feature pH: 0.0503
Feature sulphates: 0.0688
Feature alcohol: 0.1071
Feature acidity_level: 0.0622
Feature total_sulfur: 0.0618
Feature sugar_alcohol_interaction: 0.0648
Feature density_ph_interaction: 0.0627
 View run skillful-stork-183 at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/37/runs/881ab551668540a68dc86acfe1dcf93c
 View experiment at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/37
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">f1_score</span>
<span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>

<span class="c1"># Load your dataframe (make sure to load it correctly)</span>
<span class="c1"># df = pd.read_csv(&#39;your_data.csv&#39;)  # Uncomment and adjust if needed</span>

<span class="c1"># Define features (X) and target variable (y)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;quality&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">]</span>

<span class="c1"># Standardize numerical features</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Perform PCA</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">()</span>
<span class="n">X_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>
<span class="n">explained_variance_ratio</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span>
<span class="n">cumulative_explained_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">explained_variance_ratio</span><span class="p">)</span>

<span class="c1"># Determine number of components for 95% variance</span>
<span class="n">num_components</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cumulative_explained_variance</span> <span class="o">&gt;=</span> <span class="mf">0.95</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

<span class="c1"># Reduce dimensions using PCA</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">num_components</span><span class="p">)</span>
<span class="n">X_reduced</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">)</span>

<span class="c1"># Split data into training and testing sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_reduced</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Train a model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Make predictions</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Calculate metrics</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>

<span class="c1"># Scree plot creation</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">explained_variance_ratio</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">cumulative_explained_variance</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;95% Variance Threshold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Scree Plot&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Principal Components&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Cumulative Explained Variance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">scree_plot_path</span> <span class="o">=</span> <span class="s1">&#39;scree_plot.png&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">scree_plot_path</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># PCA 2D scatter plot (first two principal components)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_reduced</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_reduced</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;PCA 2D Scatter Plot&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Principal Component 1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Principal Component 2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Quality&#39;</span><span class="p">)</span>
<span class="n">pca_scatter_plot_path</span> <span class="o">=</span> <span class="s1">&#39;pca_scatter_plot.png&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">pca_scatter_plot_path</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># PCA graph showing variance up to 95%</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_components</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">cumulative_explained_variance</span><span class="p">[:</span><span class="n">num_components</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;95% Variance Threshold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;PCA Components up to 95% Variance (</span><span class="si">{</span><span class="n">num_components</span><span class="si">}</span><span class="s1"> Components)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Principal Components&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Cumulative Explained Variance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">pca_95_variance_plot_path</span> <span class="o">=</span> <span class="s1">&#39;pca_95_variance_plot.png&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">pca_95_variance_plot_path</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># Print feature contributions to each principal component</span>
<span class="n">components_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Feature contributions to principal components (loadings):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">components_df</span><span class="p">)</span>

<span class="c1"># MLFlow experiment setup</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s1">&#39;Experiment #5: PCA for Dimensionality Reductions!!&#39;</span><span class="p">)</span>

<span class="c1"># Log results in MLFlow</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>
    <span class="c1"># Log PCA explained variance metrics</span>
    <span class="n">explained_variance_95</span> <span class="o">=</span> <span class="n">cumulative_explained_variance</span><span class="p">[</span><span class="n">num_components</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;explained_variance_95&#39;</span><span class="p">,</span> <span class="n">explained_variance_95</span><span class="p">)</span>  <span class="c1"># Removed &#39;%&#39; from the name</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_param</span><span class="p">(</span><span class="s1">&#39;num_components&#39;</span><span class="p">,</span> <span class="n">num_components</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">explained_variance_ratio</span><span class="p">[:</span><span class="n">num_components</span><span class="p">]):</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;pca_explained_variance_ratio_component_</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span>

    <span class="c1"># Log model</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;random_forest_model&#39;</span><span class="p">)</span>

    <span class="c1"># Log metrics</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;f1_score&#39;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>

    <span class="c1"># Log scree plot, PCA scatter plot, and PCA 95% variance plot as artifacts</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="n">scree_plot_path</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="n">pca_scatter_plot_path</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="n">pca_95_variance_plot_path</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Explained Variance (95%): </span><span class="si">{</span><span class="n">explained_variance_95</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of Components: </span><span class="si">{</span><span class="n">num_components</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;F1 Score: </span><span class="si">{</span><span class="n">f1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Scree plot, PCA scatter plot, and PCA 95% variance plot saved and logged to MLflow.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Feature contributions to principal components (loadings):
   wine_type  fixed_acidity  volatile_acidity  citric_acid  residual_sugar  \
0  -0.376510      -0.209481         -0.268523     0.088067        0.273547   
1   0.127173       0.386896          0.059309     0.237223        0.273613   
2   0.147960      -0.212640          0.225782    -0.285011        0.245541   
3  -0.003070       0.109543         -0.226919     0.406854       -0.290201   
4  -0.029756       0.142707         -0.249838     0.349996        0.276332   
5  -0.016326      -0.333178         -0.164490     0.118012        0.190706   
6   0.135832       0.120412          0.484544    -0.273242        0.062839   
7   0.022411      -0.081428          0.277728     0.413060        0.051417   
8   0.203583       0.164335         -0.550600    -0.366430        0.037145   

   chlorides  free_sulfur_dioxide  total_sulfur_dioxide   density        pH  \
0  -0.204579             0.316441              0.378023 -0.043852 -0.166178   
1   0.212959             0.037121              0.052947  0.444187 -0.266721   
2   0.126473             0.123218              0.092788  0.351861  0.428103   
3   0.172800             0.333799              0.256036 -0.051478  0.245258   
4  -0.412263            -0.148941             -0.141824  0.084457  0.292154   
5   0.436389            -0.123177             -0.139670 -0.088147 -0.157644   
6  -0.108926             0.342236              0.146483 -0.125248 -0.090973   
7   0.555197             0.067091              0.006142 -0.100331  0.102645   
8   0.236732             0.518888             -0.306315  0.021502  0.010900   

   sulphates   alcohol  acidity_level  total_sulfur  \
0  -0.210295 -0.072173      -0.218290      0.383279   
1   0.127451 -0.298494       0.393237      0.051868   
2   0.099925 -0.287159      -0.201667      0.105561   
3   0.405075 -0.006084       0.117993      0.289717   
4   0.048302  0.405166       0.140298     -0.151415   
5   0.567170  0.188604      -0.318350     -0.143190   
6   0.259771  0.565967       0.141335      0.203889   
7  -0.563016  0.268840       0.000128      0.021846   
8  -0.193193  0.130896       0.049824     -0.115106   

   sugar_alcohol_interaction  density_ph_interaction  
0                   0.269883               -0.168583  
1                   0.247998               -0.239447  
2                   0.220261                0.448056  
3                  -0.311286                0.241318  
4                   0.340354                0.296286  
5                   0.219201               -0.162739  
6                   0.142357               -0.098161  
7                   0.100384                0.096282  
8                   0.051941                0.012375  
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/20 09:17:30 INFO mlflow.tracking.fluent: Experiment with name &#39;Experiment #5: PCA for Dimensionality Reductions!!&#39; does not exist. Creating a new experiment.
2024/12/20 09:17:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Explained Variance (95%): 0.9707
Number of Components: 9
Accuracy: 0.6762
F1 Score: 0.6633
Scree plot, PCA scatter plot, and PCA 95% variance plot saved and logged to MLflow.
 View run gaudy-rat-340 at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/38/runs/d111469884b94913a7ac2f77df038843
 View experiment at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/38
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">label_binarize</span>

<span class="c1"># Set the experiment name in MLFlow</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s1">&#39;#6 SVC_Custom_Experiments!&#39;</span><span class="p">)</span>

<span class="c1"># Preprocessing</span>
<span class="c1"># Assume &#39;quality&#39; is the target variable and all others are features</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;quality&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">]</span>

<span class="c1"># Encoding the target variable if it&#39;s categorical</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y_encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># Encode categorical labels</span>

<span class="c1"># Standardizing the features</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Split the dataset into training and testing sets (Stratified Split to ensure all classes are represented)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y_encoded</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y_encoded</span><span class="p">)</span>

<span class="c1"># Start the MLFlow experiment run</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>

    <span class="c1"># Define the Support Vector Classifier (SVC) model</span>
    <span class="n">model_svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    
    <span class="c1"># Train the model</span>
    <span class="n">model_svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Make predictions on the test set</span>
    <span class="n">y_pred_svc</span> <span class="o">=</span> <span class="n">model_svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    
    <span class="c1"># Calculate various metrics</span>
    <span class="n">accuracy_svc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_svc</span><span class="p">)</span>
    <span class="n">f1_svc</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_svc</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>

    <span class="c1"># Binarize the labels for ROC AUC calculation (only if it&#39;s a multi-class classification)</span>
    <span class="n">y_bin</span> <span class="o">=</span> <span class="n">label_binarize</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_encoded</span><span class="p">))</span>
    
    <span class="c1"># Calculate ROC AUC if there are at least two classes</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">roc_auc_svc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_bin</span><span class="p">,</span> <span class="n">model_svc</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;ovr&#39;</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;SVC_roc_auc&#39;</span><span class="p">,</span> <span class="n">roc_auc_svc</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: Only one class present in y_test, ROC AUC not calculated.&quot;</span><span class="p">)</span>
        <span class="n">roc_auc_svc</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Log metrics in MLFlow</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;SVC_accuracy&#39;</span><span class="p">,</span> <span class="n">accuracy_svc</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;SVC_f1_score&#39;</span><span class="p">,</span> <span class="n">f1_svc</span><span class="p">)</span>

    <span class="c1"># Log the trained model in MLFlow</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">model_svc</span><span class="p">,</span> <span class="s1">&#39;SupportVectorClassifier&#39;</span><span class="p">)</span>

    <span class="c1"># Confusion Matrix</span>
    <span class="n">conf_matrix_svc</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_svc</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">conf_matrix_svc</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>  <span class="c1"># Binary classification</span>
        <span class="n">tn_svc</span><span class="p">,</span> <span class="n">fp_svc</span><span class="p">,</span> <span class="n">fn_svc</span><span class="p">,</span> <span class="n">tp_svc</span> <span class="o">=</span> <span class="n">conf_matrix_svc</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SVC Confusion Matrix Components:&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  True Negatives (TN): </span><span class="si">{</span><span class="n">tn_svc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  False Positives (FP): </span><span class="si">{</span><span class="n">fp_svc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  False Negatives (FN): </span><span class="si">{</span><span class="n">fn_svc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  True Positives (TP): </span><span class="si">{</span><span class="n">tp_svc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;SVC Confusion Matrix (Multi-Class):&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">conf_matrix_svc</span><span class="p">)</span>

    <span class="c1"># Plot the confusion matrix</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">conf_matrix_svc</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix: Support Vector Classifier&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">)),</span> <span class="n">encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">)),</span> <span class="n">encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">conf_matrix_path_svc</span> <span class="o">=</span> <span class="s1">&#39;SVC_confusion_matrix.png&#39;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">conf_matrix_path_svc</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="c1"># Log confusion matrix as an artifact</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="n">conf_matrix_path_svc</span><span class="p">)</span>

    <span class="c1"># Print results</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Support Vector Classifier Results:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Accuracy: </span><span class="si">{</span><span class="n">accuracy_svc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  F1 Score: </span><span class="si">{</span><span class="n">f1_svc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">roc_auc_svc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  ROC AUC: </span><span class="si">{</span><span class="n">roc_auc_svc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion matrix logged to MLFlow.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/20 09:17:58 INFO mlflow.tracking.fluent: Experiment with name &#39;#6 SVC_Custom_Experiments!&#39; does not exist. Creating a new experiment.
2024/12/20 09:18:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SVC Confusion Matrix (Multi-Class):
[[  0   0   3   3   0   0   0]
 [  0   0  30  12   1   0   0]
 [  0   0 282 146   0   0   0]
 [  0   0 128 414  25   0   0]
 [  0   0  11 158  47   0   0]
 [  0   0   0  26  13   0   0]
 [  0   0   0   1   0   0   0]]
Support Vector Classifier Results:
  Accuracy: 0.5715
  F1 Score: 0.5344
  ROC AUC: 0.8239
Confusion matrix logged to MLFlow.
 View run popular-stag-48 at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/39/runs/e836aecf093148eda39e226841da5a22
 View experiment at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/39
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">label_binarize</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Set the experiment name in MLFlow</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s1">&#39;7 KNN_vs_SVM_Custom_Experiments!&#39;</span><span class="p">)</span>


<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;quality&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">]</span>

<span class="c1"># Encode the target variable if it&#39;s categorical</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y_encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># Encode categorical labels</span>

<span class="c1"># Standardize the features</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Split the dataset into training and testing sets (Stratified Split to ensure all classes are represented)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y_encoded</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y_encoded</span><span class="p">)</span>

<span class="c1"># Start the MLFlow experiment run</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>

    <span class="c1">### K-Nearest Neighbors (KNN) ###</span>
    <span class="c1"># Define the KNN model</span>
    <span class="n">model_knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    
    <span class="c1"># Train the KNN model</span>
    <span class="n">model_knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Make predictions on the test set</span>
    <span class="n">y_pred_knn</span> <span class="o">=</span> <span class="n">model_knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    
    <span class="c1"># Calculate metrics for KNN</span>
    <span class="n">accuracy_knn</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_knn</span><span class="p">)</span>
    <span class="n">f1_knn</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_knn</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>

    <span class="c1"># Binarize the labels for ROC AUC calculation (only if it&#39;s a multi-class classification)</span>
    <span class="n">y_bin</span> <span class="o">=</span> <span class="n">label_binarize</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_encoded</span><span class="p">))</span>
    
    <span class="c1"># Calculate ROC AUC if there are at least two classes</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">roc_auc_knn</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_bin</span><span class="p">,</span> <span class="n">model_knn</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;ovr&#39;</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;KNN_roc_auc&#39;</span><span class="p">,</span> <span class="n">roc_auc_knn</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: Only one class present in y_test, ROC AUC not calculated.&quot;</span><span class="p">)</span>
        <span class="n">roc_auc_knn</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Log metrics for KNN</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;KNN_accuracy&#39;</span><span class="p">,</span> <span class="n">accuracy_knn</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;KNN_f1_score&#39;</span><span class="p">,</span> <span class="n">f1_knn</span><span class="p">)</span>

    <span class="c1"># Log the trained KNN model in MLFlow</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">model_knn</span><span class="p">,</span> <span class="s1">&#39;KNN_Classifier&#39;</span><span class="p">)</span>

    <span class="c1"># Confusion Matrix for KNN</span>
    <span class="n">conf_matrix_knn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_knn</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">conf_matrix_knn</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>  <span class="c1"># Binary classification</span>
        <span class="n">tn_knn</span><span class="p">,</span> <span class="n">fp_knn</span><span class="p">,</span> <span class="n">fn_knn</span><span class="p">,</span> <span class="n">tp_knn</span> <span class="o">=</span> <span class="n">conf_matrix_knn</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;KNN Confusion Matrix Components:&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  True Negatives (TN): </span><span class="si">{</span><span class="n">tn_knn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  False Positives (FP): </span><span class="si">{</span><span class="n">fp_knn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  False Negatives (FN): </span><span class="si">{</span><span class="n">fn_knn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  True Positives (TP): </span><span class="si">{</span><span class="n">tp_knn</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;KNN Confusion Matrix (Multi-Class):&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">conf_matrix_knn</span><span class="p">)</span>

    <span class="c1"># Plot and log confusion matrix for KNN</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">conf_matrix_knn</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix: K-Nearest Neighbors&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">)),</span> <span class="n">encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">)),</span> <span class="n">encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">conf_matrix_path_knn</span> <span class="o">=</span> <span class="s1">&#39;KNN_confusion_matrix.png&#39;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">conf_matrix_path_knn</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="c1"># Log confusion matrix as an artifact</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="n">conf_matrix_path_knn</span><span class="p">)</span>

    <span class="c1">### Support Vector Machine (SVM) ###</span>
    <span class="c1"># Define the SVM model</span>
    <span class="n">model_svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    
    <span class="c1"># Train the SVM model</span>
    <span class="n">model_svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># Make predictions on the test set</span>
    <span class="n">y_pred_svm</span> <span class="o">=</span> <span class="n">model_svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    
    <span class="c1"># Calculate metrics for SVM</span>
    <span class="n">accuracy_svm</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_svm</span><span class="p">)</span>
    <span class="n">f1_svm</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_svm</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>

    <span class="c1"># Calculate ROC AUC for SVM</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">roc_auc_svm</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_bin</span><span class="p">,</span> <span class="n">model_svm</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;ovr&#39;</span><span class="p">)</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;SVM_roc_auc&#39;</span><span class="p">,</span> <span class="n">roc_auc_svm</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: Only one class present in y_test, ROC AUC not calculated.&quot;</span><span class="p">)</span>
        <span class="n">roc_auc_svm</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Log metrics for SVM</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;SVM_accuracy&#39;</span><span class="p">,</span> <span class="n">accuracy_svm</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;SVM_f1_score&#39;</span><span class="p">,</span> <span class="n">f1_svm</span><span class="p">)</span>

    <span class="c1"># Log the trained SVM model in MLFlow</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">model_svm</span><span class="p">,</span> <span class="s1">&#39;SVM_Classifier&#39;</span><span class="p">)</span>

    <span class="c1"># Confusion Matrix for SVM</span>
    <span class="n">conf_matrix_svm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_svm</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">conf_matrix_svm</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>  <span class="c1"># Binary classification</span>
        <span class="n">tn_svm</span><span class="p">,</span> <span class="n">fp_svm</span><span class="p">,</span> <span class="n">fn_svm</span><span class="p">,</span> <span class="n">tp_svm</span> <span class="o">=</span> <span class="n">conf_matrix_svm</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SVM Confusion Matrix Components:&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  True Negatives (TN): </span><span class="si">{</span><span class="n">tn_svm</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  False Positives (FP): </span><span class="si">{</span><span class="n">fp_svm</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  False Negatives (FN): </span><span class="si">{</span><span class="n">fn_svm</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  True Positives (TP): </span><span class="si">{</span><span class="n">tp_svm</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;SVM Confusion Matrix (Multi-Class):&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">conf_matrix_svm</span><span class="p">)</span>

    <span class="c1"># Plot and log confusion matrix for SVM</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">conf_matrix_svm</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix: Support Vector Machine&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">)),</span> <span class="n">encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">)),</span> <span class="n">encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">conf_matrix_path_svm</span> <span class="o">=</span> <span class="s1">&#39;SVM_confusion_matrix.png&#39;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">conf_matrix_path_svm</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="c1"># Log confusion matrix as an artifact</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="n">conf_matrix_path_svm</span><span class="p">)</span>

    <span class="c1"># Print results for KNN and SVM</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;KNN Results:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Accuracy: </span><span class="si">{</span><span class="n">accuracy_knn</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  F1 Score: </span><span class="si">{</span><span class="n">f1_knn</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">roc_auc_knn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  ROC AUC: </span><span class="si">{</span><span class="n">roc_auc_knn</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SVM Results:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Accuracy: </span><span class="si">{</span><span class="n">accuracy_svm</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  F1 Score: </span><span class="si">{</span><span class="n">f1_svm</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">roc_auc_svm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  ROC AUC: </span><span class="si">{</span><span class="n">roc_auc_svm</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion matrices logged to MLFlow.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/20 09:18:53 INFO mlflow.tracking.fluent: Experiment with name &#39;7 KNN_vs_SVM_Custom_Experiments!&#39; does not exist. Creating a new experiment.
2024/12/20 09:19:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>KNN Confusion Matrix (Multi-Class):
[[  0   1   3   2   0   0   0]
 [  1   4  22  16   0   0   0]
 [  0   9 284 123  12   0   0]
 [  0   5 177 333  52   0   0]
 [  0   0  24 101  89   2   0]
 [  0   1   1  13  21   3   0]
 [  0   0   0   0   1   0   0]]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/20 09:20:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>SVM Confusion Matrix (Multi-Class):
[[  0   0   2   4   0   0   0]
 [  0   0  28  15   0   0   0]
 [  0   0 266 162   0   0   0]
 [  0   0 147 420   0   0   0]
 [  0   0  20 196   0   0   0]
 [  0   0   2  37   0   0   0]
 [  0   0   0   1   0   0   0]]
KNN Results:
  Accuracy: 0.5485
  F1 Score: 0.5346
  ROC AUC: 0.6848
SVM Results:
  Accuracy: 0.5277
  F1 Score: 0.4575
  ROC AUC: 0.7806
Confusion matrices logged to MLFlow.
 View run debonair-snake-958 at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/40/runs/ad84814642074d05b86a69369fcdf0bd
 View experiment at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/40
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">RidgeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>

<span class="c1"># Set the experiment name in MLFlow</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s1">&#39;#8 Model_Comparison_Experiments!!!!!&#39;</span><span class="p">)</span>

<span class="c1"># Sample dataset (replace with your actual dataset)</span>
<span class="c1"># Assuming &#39;df&#39; is your DataFrame with &#39;quality&#39; as target variable</span>
<span class="c1"># Ensure that &#39;df&#39; is already defined with the proper data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;quality&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">]</span>

<span class="c1"># Encode the target variable if it&#39;s categorical</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y_encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># Encode categorical labels</span>

<span class="c1"># Standardize the features</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Split the dataset into training and testing sets (Stratified Split)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y_encoded</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y_encoded</span><span class="p">)</span>

<span class="c1"># Store F1-scores for comparison</span>
<span class="n">model_names</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">f1_scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Function to train and evaluate a model</span>
<span class="k">def</span> <span class="nf">train_and_evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>
    <span class="n">model_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">f1_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">f1</span>

<span class="c1"># Start the MLFlow experiment run</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>

    <span class="c1"># 1. Random Forest Model</span>
    <span class="n">model_rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">f1_rf</span> <span class="o">=</span> <span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">model_rf</span><span class="p">,</span> <span class="s1">&#39;Random Forest&#39;</span><span class="p">)</span>

    <span class="c1"># 2. Logistic Regression Model</span>
    <span class="n">model_lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="n">f1_lr</span> <span class="o">=</span> <span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">model_lr</span><span class="p">,</span> <span class="s1">&#39;Logistic Regression&#39;</span><span class="p">)</span>

    <span class="c1"># 3. SVC Model</span>
    <span class="n">model_svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">f1_svc</span> <span class="o">=</span> <span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">model_svc</span><span class="p">,</span> <span class="s1">&#39;SVC&#39;</span><span class="p">)</span>

    <span class="c1"># 4. Ridge Classifier Model</span>
    <span class="n">model_ridge</span> <span class="o">=</span> <span class="n">RidgeClassifier</span><span class="p">()</span>
    <span class="n">f1_ridge</span> <span class="o">=</span> <span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">model_ridge</span><span class="p">,</span> <span class="s1">&#39;Ridge Classifier&#39;</span><span class="p">)</span>

    <span class="c1"># 5. XGBoost Classifier Model</span>
    <span class="n">model_xgb</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">f1_xgb</span> <span class="o">=</span> <span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">model_xgb</span><span class="p">,</span> <span class="s1">&#39;XGBoost&#39;</span><span class="p">)</span>

    <span class="c1"># Create a DataFrame to store the results</span>
    <span class="n">results_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
        <span class="s1">&#39;Model&#39;</span><span class="p">:</span> <span class="n">model_names</span><span class="p">,</span>
        <span class="s1">&#39;F1 Score&#39;</span><span class="p">:</span> <span class="n">f1_scores</span>
    <span class="p">})</span>

    <span class="c1"># Log F1-scores in MLFlow</span>
    <span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">f1</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">model_names</span><span class="p">,</span> <span class="n">f1_scores</span><span class="p">):</span>
        <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s1">_f1_score&#39;</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>

    <span class="c1"># Plot the F1-scores using a bar chart</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">results_df</span><span class="p">[</span><span class="s1">&#39;Model&#39;</span><span class="p">],</span> <span class="n">results_df</span><span class="p">[</span><span class="s1">&#39;F1 Score&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;purple&#39;</span><span class="p">,</span> <span class="s1">&#39;orange&#39;</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model Comparison: F1 Score&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;F1 Score&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

    <span class="c1"># Save the plot as an artifact</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;F1_score_comparison_plot.png&#39;</span><span class="p">)</span>

    <span class="c1"># Log the plot as an artifact in MLFlow</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="s1">&#39;F1_score_comparison_plot.png&#39;</span><span class="p">)</span>

    <span class="c1"># Show the plot</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Experiment and results logged to MLFlow.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/20 11:53:32 INFO mlflow.tracking.fluent: Experiment with name &#39;#8 Model_Comparison_Experiments!!!!!&#39; does not exist. Creating a new experiment.
</pre></div>
</div>
<img alt="_images/7300f9a62bb75903002629f2aa493cb841cbba83d857ff60e2756d3a7265fc99.png" src="_images/7300f9a62bb75903002629f2aa493cb841cbba83d857ff60e2756d3a7265fc99.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Experiment and results logged to MLFlow.
 View run delicate-kit-748 at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/45/runs/51f321cec31b449d93c370f6d3d6cefa
 View experiment at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/45
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mlflow</span>
<span class="kn">import</span> <span class="nn">mlflow.sklearn</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">accuracy_score</span>

<span class="c1"># Set the experiment name in MLFlow</span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_experiment</span><span class="p">(</span><span class="s1">&#39;#9 random_Experiment&#39;</span><span class="p">)</span>

<span class="c1"># Sample dataset (replace with your actual dataset)</span>
<span class="c1"># Assuming &#39;df&#39; is your DataFrame with &#39;quality&#39; as the target variable</span>
<span class="c1"># Ensure that &#39;df&#39; is already defined with the proper data</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;quality&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">]</span>

<span class="c1"># Encode the target variable if it&#39;s categorical</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y_encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># Encode categorical labels</span>

<span class="c1"># Standardize the features</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Split the dataset into training and testing sets (Stratified Split)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y_encoded</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y_encoded</span><span class="p">)</span>

<span class="c1"># Function to train and evaluate a model</span>
<span class="k">def</span> <span class="nf">train_and_evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">f1</span><span class="p">,</span> <span class="n">accuracy</span>

<span class="c1"># Start the MLFlow experiment run</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>

    <span class="c1"># 1. Random Forest Model</span>
    <span class="n">model_rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
    <span class="n">f1_rf</span><span class="p">,</span> <span class="n">accuracy_rf</span> <span class="o">=</span> <span class="n">train_and_evaluate</span><span class="p">(</span><span class="n">model_rf</span><span class="p">,</span> <span class="s1">&#39;Random Forest&#39;</span><span class="p">)</span>

    <span class="c1"># Log the F1 score and accuracy of the Random Forest model</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;Random_Forest_f1_score&#39;</span><span class="p">,</span> <span class="n">f1_rf</span><span class="p">)</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s1">&#39;Random_Forest_accuracy&#39;</span><span class="p">,</span> <span class="n">accuracy_rf</span><span class="p">)</span>

    <span class="c1"># Log the Random Forest model</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">model_rf</span><span class="p">,</span> <span class="s2">&quot;random_forest_model&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Random Forest Model F1 Score: </span><span class="si">{</span><span class="n">f1_rf</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Random Forest Model Accuracy: </span><span class="si">{</span><span class="n">accuracy_rf</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Random Forest model logged to MLFlow.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024/12/20 12:11:49 INFO mlflow.tracking.fluent: Experiment with name &#39;#9 random_Experiment&#39; does not exist. Creating a new experiment.
2024/12/20 12:12:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random Forest Model F1 Score: 0.6695501279135309
Random Forest Model Accuracy: 0.6807692307692308
Random Forest model logged to MLFlow.
 View run beautiful-ox-574 at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/48/runs/b16713df23474ea0965a9153b7e97362
 View experiment at: https://dagshub.com/shubh0000007/my-first-repo.mlflow/#/experiments/48
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model_rf</span><span class="p">,</span> <span class="s1">&#39;random_forest_model.pkl&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;random_forest_model.pkl&#39;]
</pre></div>
</div>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Projectlinks.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Project Links</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>